{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Analyse kernel profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Sample cmd \n",
    "```\n",
    "ck benchmark program:caffe --env.CK_CAFFE_BATCH_SIZE=1 \\\n",
    "  --deps.lib-caffe=cb3e77cde4b54140 --deps.caffemodel=ae96844061a5678d \\\n",
    "  --cmd_key=time_gpu --dvdt_prof --skip_stat_analysis \\\n",
    "  --tags=prof,alexnet --record --record_uoa=prof-training-alexnet \\\n",
    "  --repetitions=3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Scientific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import IPython as ip\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('IPython version: %s' % ip.__version__)\n",
    "print('NumPy version: %s' % np.__version__)\n",
    "print('SciPy version: %s' % sp.__version__)\n",
    "print('Pandas version: %s' % pd.__version__)\n",
    "print('Matplotlib version: %s' % mp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "# import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Collective Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import ck.kernel as ck\n",
    "print('CK version: %s' % ck.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Access experimental results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_experimental_results(tags):\n",
    "    search = 'search'\n",
    "    repo_uoa = 'local'\n",
    "    module_uoa = 'experiment'\n",
    "    r=ck.access({'action':search, 'module_uoa':module_uoa, 'tags':tags})\n",
    "    if r['return']>0:\n",
    "        print (\"Error: %s\" % r['error'])\n",
    "        exit(1)\n",
    "    experiments=r['lst']\n",
    "    dfs = []\n",
    "    for experiment in experiments:\n",
    "        data_uoa = experiment['data_uoa']\n",
    "        r = ck.access({'action':'list_points', 'repo_oua':repo_uoa, 'module_uoa':module_uoa, 'data_uoa':data_uoa})\n",
    "        if r['return']>0:\n",
    "            print (\"Error: %s\" % r['error'])\n",
    "            exit(1)\n",
    "        path = r['path']\n",
    "        points = r['points']\n",
    "        for point in points:\n",
    "            with open(os.path.join(path, 'ckp-%s.0001.json' % point)) as point_file:\n",
    "                point_data_raw = json.load(point_file)\n",
    "            # DataFrame columns.\n",
    "            characteristics = [\n",
    "                {\n",
    "                    'time (ms)'   : np.float32(characteristics['run'].get('time_fw_ms',0)),\n",
    "                    'per_layer_info': characteristics['run'].get('per_layer_info',[]),\n",
    "                    'dvdt_prof'   : characteristics['run'].get('dvdt_prof',[])\n",
    "                }\n",
    "                for characteristics in point_data_raw['characteristics_list'] \n",
    "                if characteristics['run'].get('run_success','')!=''\n",
    "            ]\n",
    "            df = pd.DataFrame(characteristics)\n",
    "            df.columns.name = 'run characteristic'\n",
    "            df.index.name = 'repetition'\n",
    "            # DataFrame indices.\n",
    "            df['program'] = point_data_raw['choices']['data_uoa']\n",
    "            df['tags'] = 'unknown'\n",
    "            df = df.set_index(['program','tags'], append=True)\n",
    "            df = df.reorder_levels(('program', 'tags', 'repetition'))\n",
    "            dfs.append(df)\n",
    "    results = pd.concat(dfs)\n",
    "#     for i in characteristics:\n",
    "#         print i['per_layer_info']\n",
    "#         print \"###############################################################################\"\n",
    "#         print i['dvdt_prof']\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = get_experimental_results('alexnet,prof')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Show execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results[['time (ms)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results[['dvdt_prof']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Plot execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot(mean, std):\n",
    "    mean \\\n",
    "        .plot(yerr=std, title='Execution time (ms)', kind='bar', colormap=cm.autumn,\n",
    "            figsize=[16, 8], rot=0, grid=True, legend=True) \\\n",
    "        .legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Show profiling info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Pick the first repetition of the first experiment for now.\n",
    "trace = results['dvdt_prof'].iloc[0]\n",
    "trace_layer = results['per_layer_info'].iloc[0]\n",
    "if not trace:\n",
    "    raise Exception(\"No OpenCL profiling information!\")\n",
    "# What's that experiment, by the way?\n",
    "results['dvdt_prof'].index[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "r=ck.access({'action':'show', 'module_uoa':'env', 'tags':'tool,opencl,dvdt,prof'})\n",
    "if r['return']>0:\n",
    "    print (\"Error: %s\" % r['error'])\n",
    "    exit(1)\n",
    "# Get path the first returned environment entry.\n",
    "dvdt_prof_dir=r['lst'][0]['meta']['env']['CK_ENV_TOOL_DVDT_PROF']\n",
    "dvdt_prof_src_python=os.path.join(dvdt_prof_dir,'src','python')\n",
    "sys.path.append(dvdt_prof_src_python)\n",
    "import prof_wrangler as pw\n",
    "pw.test()\n",
    "import prof_common as pc\n",
    "pc.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trace = pw.index_calls(trace)\n",
    "unit = 'ms'\n",
    "trace_layer = pw.index_calls(trace_layer)\n",
    "unit2 = 'ms'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print len(trace)\n",
    "print len(trace_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Kernel enqueues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Partial trace only containing kernel enqueues.\n",
    "kernel_enqueues = pw.filter_calls(trace, ['clEnqueueNDRangeKernel'])\n",
    "# Kernel enqueues as a DataFrame.\n",
    "df_kernel_enqueues = pw.df_kernel_enqueues(kernel_enqueues, unit)\n",
    "df_kernel_enqueues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_kernel_enqueues['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_kernel_enqueues.groupby(level='name').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df_kernel_enqueues.info(memory_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_enqueues_total = len(kernel_enqueues)\n",
    "num_enqueues_per_repetition = 4\n",
    "df_kernel_enqueues['kernel_index'] = (pd.Series(range(num_enqueues_total)) % num_enqueues_per_repetition).values\n",
    "df_kernel_enqueues = df_kernel_enqueues \\\n",
    "    .set_index('kernel_index', append=True) \\\n",
    "    .reorder_levels(['call_index','kernel_index','name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_kernel_enqueues_stats = df_kernel_enqueues.groupby(level='kernel_index').describe()\n",
    "df_kernel_enqueues_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERNEL XgemmDirectNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Partial trace only containing kernel enqueues.\n",
    "kernel_enqueues = pw.filter_calls(trace, ['clEnqueueNDRangeKernel'])\n",
    "# Kernel enqueues as a DataFrame.\n",
    "df_kernel_enqueues = pw.df_kernel_enqueues(kernel_enqueues, unit)\n",
    "df_xgemm_directnn_enqueues = df_kernel_enqueues.swaplevel().ix['XgemmDirectNN']\n",
    "df_xgemm_directnn_enqueues\n",
    "df_xgemm_directnn_enqueues['kSizeM'] = 'N/A'\n",
    "df_xgemm_directnn_enqueues['kSizeN'] = 'N/A'\n",
    "df_xgemm_directnn_enqueues['kSizeK'] = 'N/A'\n",
    "\n",
    "setkernel_enqueues = pw.filter_calls(trace, ['clSetKernelArg'])\n",
    "kernel_entries = pw.filter_calls(trace, ['clEnqueueNDRangeKernel'])\n",
    "xgemm_entries = []\n",
    "for kernel_count in kernel_entries:\n",
    "    if kernel_count['name'] == 'XgemmDirectNN':\n",
    "        xgemm_index = kernel_count['kernel']\n",
    "        xgemm_matrix_sizes = []\n",
    "        for k in setkernel_enqueues:\n",
    "            if (k['kernel'] == xgemm_index) and (k['arg_index'] == 0 or k['arg_index'] == 1 or k['arg_index'] == 2):\n",
    "                tmp = pc.hex_str_as_int(k['arg_value'])\n",
    "                xgemm_matrix_sizes.append(tmp)\n",
    "        entry_matrix_sizes = tuple(xgemm_matrix_sizes)\n",
    "        xgemm_entries.append(entry_matrix_sizes)\n",
    "print len(xgemm_entries)\n",
    "\n",
    "df_xgemm_directnn_enqueues[['kSizeM', 'kSizeN', 'kSizeK']] = xgemm_entries\n",
    "df_xgemm_directnn_enqueues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERNEL XgemmDirectTN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Partial trace only containing kernel enqueues.\n",
    "kernel_enqueues = pw.filter_calls(trace, ['clEnqueueNDRangeKernel'])\n",
    "# Kernel enqueues as a DataFrame.\n",
    "df_kernel_enqueues = pw.df_kernel_enqueues(kernel_enqueues, unit)\n",
    "df_xgemm_directnn_enqueues = df_kernel_enqueues.swaplevel().ix['XgemmDirectTN']\n",
    "df_xgemm_directnn_enqueues\n",
    "df_xgemm_directnn_enqueues['kSizeM'] = 'N/A'\n",
    "df_xgemm_directnn_enqueues['kSizeN'] = 'N/A'\n",
    "df_xgemm_directnn_enqueues['kSizeK'] = 'N/A'\n",
    "\n",
    "setkernel_enqueues = pw.filter_calls(trace, ['clSetKernelArg'])\n",
    "kernel_entries = pw.filter_calls(trace, ['clEnqueueNDRangeKernel'])\n",
    "xgemm_entries = []\n",
    "for kernel_count in kernel_entries:\n",
    "    if kernel_count['name'] == 'XgemmDirectTN':\n",
    "        xgemm_index = kernel_count['kernel']\n",
    "        xgemm_matrix_sizes = []\n",
    "        for k in setkernel_enqueues:\n",
    "            if (k['kernel'] == xgemm_index) and (k['arg_index'] == 0 or k['arg_index'] == 1 or k['arg_index'] == 2):\n",
    "                tmp = pc.hex_str_as_int(k['arg_value'])\n",
    "                xgemm_matrix_sizes.append(tmp)\n",
    "        entry_matrix_sizes = tuple(xgemm_matrix_sizes)\n",
    "        xgemm_entries.append(entry_matrix_sizes)\n",
    "print len(xgemm_entries)\n",
    "\n",
    "df_xgemm_directnn_enqueues[['kSizeM', 'kSizeN', 'kSizeK']] = xgemm_entries\n",
    "df_xgemm_directnn_enqueues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERNEL XgemmDirectTT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Partial trace only containing kernel enqueues.\n",
    "kernel_enqueues = pw.filter_calls(trace, ['clEnqueueNDRangeKernel'])\n",
    "# Kernel enqueues as a DataFrame.\n",
    "df_kernel_enqueues = pw.df_kernel_enqueues(kernel_enqueues, unit)\n",
    "df_xgemm_directnn_enqueues = df_kernel_enqueues.swaplevel().ix['XgemmDirectTT']\n",
    "df_xgemm_directnn_enqueues\n",
    "df_xgemm_directnn_enqueues['kSizeM'] = 'N/A'\n",
    "df_xgemm_directnn_enqueues['kSizeN'] = 'N/A'\n",
    "df_xgemm_directnn_enqueues['kSizeK'] = 'N/A'\n",
    "\n",
    "setkernel_enqueues = pw.filter_calls(trace, ['clSetKernelArg'])\n",
    "kernel_entries = pw.filter_calls(trace, ['clEnqueueNDRangeKernel'])\n",
    "xgemm_entries = []\n",
    "for kernel_count in kernel_entries:\n",
    "    if kernel_count['name'] == 'XgemmDirectTT':\n",
    "        xgemm_index = kernel_count['kernel']\n",
    "        xgemm_matrix_sizes = []\n",
    "        for k in setkernel_enqueues:\n",
    "            if (k['kernel'] == xgemm_index) and (k['arg_index'] == 0 or k['arg_index'] == 1 or k['arg_index'] == 2):\n",
    "                tmp = pc.hex_str_as_int(k['arg_value'])\n",
    "                xgemm_matrix_sizes.append(tmp)\n",
    "        entry_matrix_sizes = tuple(xgemm_matrix_sizes)\n",
    "        xgemm_entries.append(entry_matrix_sizes)\n",
    "print len(xgemm_entries)\n",
    "\n",
    "df_xgemm_directnn_enqueues[['kSizeM', 'kSizeN', 'kSizeK']] = xgemm_entries\n",
    "df_xgemm_directnn_enqueues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Kernel per layer\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convert_time(t):\n",
    "#     get hh:mm:ss:decilmals\n",
    "    h,m,s = t.split(\".\")[0].split(\":\")  #[0] hours, minutes, seconds [1] milliseconds ... \n",
    "    tsec = (int(h)*3600) + (int(m)*60) + int(s)\n",
    "    total = float(tsec) + float(\"0.\" + t.split(\".\")[1]) \n",
    "    return float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print len(trace)\n",
    "print len(trace_layer)\n",
    "epoch_layer=[]\n",
    "for tlc in trace_layer[1:len(trace_layer)]:\n",
    "    epoch_layer.append(convert_time(tlc['timestamp'].split(\" \")[1]))\n",
    "     \n",
    "print \"````````````````````````````````````\"\n",
    "print tlc['timestamp'].split(\" \")\n",
    "print \"````````````````````````````````````\"\n",
    "print trace[len(trace)-1]['timestamp']['end']\n",
    "print \"````````````````````````````````````\"  \n",
    "p = len(epoch_layer)\n",
    "last_trace = 0\n",
    "\n",
    "\n",
    "# t = trace[0]['timestamp']['end'].split(\"T\")[1]\n",
    "# t = convert_time(t)\n",
    "# print (\"first converted %s last epoch layer %s\" %(t,epoch_layer[0]))\n",
    "\n",
    "\n",
    "\n",
    "# t = trace[0]['timestamp']['end'].split(\"T\")[1]\n",
    "# t = convert_time(t)\n",
    "# print (\"second converted %s last epoch layer %s\" %(t,epoch_layer[1]))\n",
    "\n",
    "lc = 0\n",
    "for i in range (0, len(trace)):\n",
    "    t = trace[i]['timestamp']['end'].split(\"T\")[1]\n",
    "    nt = convert_time(t)\n",
    "    \n",
    "    if (nt < epoch_layer[lc]):\n",
    "        print (\"%s (%s) belongs to %s\" %(nt, trace[i]['timestamp']['end'].split(\"T\")[1],epoch_layer[lc]))\n",
    "    else:\n",
    "        print \"##############################################\"\n",
    "        print \"new layer %s ( how many trace %s)\"% (lc,i)\n",
    "        lc=lc+1\n",
    "\n",
    "\n",
    "t = trace[len(trace)-1]['timestamp']['end'].split(\"T\")[1]\n",
    "t = convert_time(t)\n",
    "print (\"last converted %s last epoch layer %s\" %(t,epoch_layer[p-1]))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
